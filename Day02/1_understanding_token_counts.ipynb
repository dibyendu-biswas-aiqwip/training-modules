{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c3585f",
   "metadata": {},
   "source": [
    "# **Understanding Token Counts & Context Window:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d600c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745accc7",
   "metadata": {},
   "source": [
    "## **Tokens:**\n",
    "\n",
    "Tokens are the basic units of text that models process. They can be as short as one character or as long as one word. <br>\n",
    "For example:\n",
    "\n",
    "* The word `\"ChatGPT\"` is one token.\n",
    "* The sentence `\"Hello, world!\"` is four tokens: `\"Hello\"`, `\",\"`, `\"world\"`, and `\"!\"`.\n",
    "\n",
    "Understanding tokenization is essential because models have limits on the number of tokens they can handle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2559e",
   "metadata": {},
   "source": [
    "## **Context Window:**\n",
    "\n",
    "A **context window** is the maximum number of tokens (chunks of text) a language model can consider at once when generating a response. It defines how much information (both input and output) the model can \"remember\" in a single request.\n",
    "\n",
    "<br>\n",
    "\n",
    "**1.** **Context Window (also called `\"context length\"`):**\n",
    "* This is the **maximum number of tokens** a language model can handle at once.\n",
    "* It includes **everything in a single prompt-response cycle**:\n",
    "    * System prompt\n",
    "    * Few-shot examples\n",
    "    * User message\n",
    "    * Model output\n",
    "* üìå Yes, it includes both `input tokens` and `output tokens`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**2.** **Input Tokens:**\n",
    "* These are the tokens you send to the model.\n",
    "* Includes:\n",
    "    * System instructions\n",
    "    * Previous chat history (if any)\n",
    "    * Current user question\n",
    "    * Few-shot examples\n",
    "* üìé This is what the model \"reads\" before generating a response.\n",
    "\n",
    "<br>\n",
    "\n",
    "**3.** **Output Tokens:**\n",
    "* These are the tokens the model generates in response.\n",
    "* The output is counted against the context window too.\n",
    "* üìé This is what the model \"writes\" back to you.\n",
    "\n",
    "<br>\n",
    "\n",
    "**üîÅ Relation:**\n",
    "* `Context Window = Input Tokens + Output Tokens`\n",
    "\n",
    "<br>\n",
    "\n",
    "**üìò Example (GPT-4o, 128,000-token context window):**\n",
    "| Component            | Token Count |\n",
    "|----------------------|-------------|\n",
    "| System prompt        | 50 tokens   |\n",
    "| Few-shot examples    | 1,000 tokens|\n",
    "| User input           | 100 tokens  |\n",
    "| Model output         | 800 tokens  |\n",
    "| **Total (Context)**  | **1,950 tokens** |\n",
    "\n",
    "<br>\n",
    "\n",
    "This is well under 128,000, so it works. <br>\n",
    "\n",
    "But if your **input = 127,000** tokens, you can only generate **1,000 output tokens max**, or the model will truncate or throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ed5d3",
   "metadata": {},
   "source": [
    "## **Calculate Tokens:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6697c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, FewShotChatMessagePromptTemplate\n",
    "from IPython.display import display, Markdown\n",
    "import asyncio\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "def load_llm(model_name:str=\"gpt-4o\", temperature: float=0.2, max_tokens:int=2000) -> OpenAI:\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=temperature, max_tokens=max_tokens)\n",
    "    return llm\n",
    "\n",
    "llm = load_llm(model_name=\"gpt-4o\", temperature=0.8, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e308af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Input Token Counts & Output Token Counts:\n",
    "\n",
    "def calculate_input_token_counts(prompt: str, user_input:str, model:str=\"gpt-4o\") -> int:\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    prompt_tokens = len(encoder.encode(prompt))\n",
    "    user_input_tokens = len(encoder.encode(user_input))\n",
    "    total_tokens = prompt_tokens + user_input_tokens\n",
    "    return total_tokens\n",
    "\n",
    "\n",
    "def calculate_output_token_counts(response: str, model:str=\"gpt-4o\") -> int:\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    prompt_tokens = len(encoder.encode(response))\n",
    "    return prompt_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23292c",
   "metadata": {},
   "source": [
    "### **Example 01:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077e316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 12\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"Count the number of tokens in a text string.\"\"\"\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain the concept of prompt engineering to a junior developer.\" # Try to experiment with this...\n",
    "token_count = count_tokens(prompt)\n",
    "print(f\"Token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7f0cd",
   "metadata": {},
   "source": [
    "### **Example 02:**\n",
    "\n",
    "* Here I use only system_prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a496a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write System Prompt:\n",
    "system_prompt = (\n",
    "    \"You are an AI Assistant named 'Lily,' specializing in answering the questions related to INDIAN History. \"\n",
    "    \"This AI Assistant is designed by Dibyendu Biswas, a Generative AI Engineer. \"\n",
    "    \"You provide clear, step-by-step explanations and encourage students to learn. \"\n",
    "    \"If a question is unclear, ask for clarification. \"\n",
    "    \"If you don't know the answer, say 'I don't know. \"\n",
    "    \"Use 5 to 10 sentences maximum and keep the answer concise. \"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffd618de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Indus Valley Civilization, also known as the Harappan Civilization, is significant in Indian history as one of the world's earliest urban cultures, flourishing around 3300 to 1300 BCE. It marks the beginning of urbanization on the Indian subcontinent, showcasing advanced city planning, with well-organized streets and sophisticated drainage systems. The civilization is noted for its impressive architectural achievements, including large public buildings, granaries, and the Great Bath of Mohenjo-Daro.\n",
       "\n",
       "The Indus Valley people were skilled in various crafts such as pottery, bead-making, and metallurgy, and they engaged in long-distance trade with neighboring regions. Their use of standard weights and measures indicates a high level of socio-economic organization. The script of the Indus Valley remains undeciphered, adding an element of mystery to their culture. Overall, the civilization sets a foundational precedent for future Indian societies in terms of technology, trade, and urban development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Token Counts:  106\n",
      "Output Token Counts:  188\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the Indus Valley Civilization in Indian history?\"\n",
    "response = chain.invoke({\"input\": query})\n",
    "response = response.content\n",
    "\n",
    "\n",
    "display(Markdown(response))\n",
    "print()\n",
    "\n",
    "print(\"Input Token Counts: \", calculate_input_token_counts(prompt=system_prompt, user_input=query))\n",
    "print(\"Output Token Counts: \", calculate_output_token_counts(response=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41387e0a",
   "metadata": {},
   "source": [
    "### **Example 03:**\n",
    "\n",
    "* Here I use both **`system_prompt`** & **`few_shot_prompt`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d0ed93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write System Prompt:\n",
    "system_prompt = (\n",
    "    \"You are an AI Assistant named 'Lily,' specializing in answering the questions related to INDIAN History. \"\n",
    "    \"This AI Assistant is designed by Dibyendu Biswas, a Generative AI Engineer. \"\n",
    "    \"You provide clear, step-by-step explanations and encourage students to learn. \"\n",
    "    \"If a question is unclear, ask for clarification. \"\n",
    "    \"If you don't know the answer, say 'I don't know. \"\n",
    "    \"Use 5 to 10 sentences maximum and keep the answer concise. \"\n",
    ")\n",
    "\n",
    "\n",
    "# Define Few-Shot Prompt Template using Few Examples:\n",
    "few_shot_examples = [\n",
    "    {'input': 'Hello', 'output': 'Hi there! How can I help you today?'},\n",
    "    {'input': 'What is your name?', 'output': 'I‚Äôm Lily, your assistant, specializing in answering the questions related to INDIAN History'},\n",
    "    {'input': 'How are you?', 'output': 'I‚Äôm doing great, thanks for asking! How about you?'},\n",
    "    {'input': 'Tell me a joke', 'output': 'Why don‚Äôt skeletons fight each other? They don‚Äôt have the guts!'},\n",
    "    {'input': 'What time is it?', 'output': 'I‚Äôm not able to tell the time, but you can check your device!'},\n",
    "    {'input': 'Goodbye', 'output': 'Goodbye! Have a great day!'},\n",
    "    {'input': 'Can you help me?', 'output': 'Of course! What do you need help with?'},\n",
    "    {'input': 'What is the weather like?', 'output': 'I‚Äôm unable to check real-time weather, but you can look it up online!'},\n",
    "    {'input': 'Set a reminder', 'output': 'I can‚Äôt set reminders, but I can help you with other things!'},\n",
    "    {'input': 'Where are you from?', 'output': 'I don‚Äôt have a specific place, but I‚Äôm here to assist you wherever you are!'},\n",
    "    {'input': 'What can you do?', 'output': 'I can answer questions, tell jokes, help with tasks, and more! What do you need today?'},\n",
    "    {'input': 'Help me with math', 'output': 'Sure! What math problem would you like help with?'},\n",
    "    {'input': 'I am bored', 'output': 'Let‚Äôs do something fun! Want to hear a joke or maybe try a quiz?'},\n",
    "    {'input': 'What is 5 + 7?', 'output': '5 + 7 equals 12!'},\n",
    "    {'input': 'How do I cook pasta?', 'output': 'Boil water, add pasta, cook for 8-12 minutes, drain, and enjoy!'},\n",
    "    {'input': 'Tell me a fun fact', 'output': 'Did you know? A day on Venus is longer than a year on Venus!'},\n",
    "    {'input': 'What is your favorite color?', 'output': 'I don‚Äôt have a favorite color, but I think blue is nice!'}\n",
    "]\n",
    "\n",
    "# Few Shot Template:\n",
    "few_shot_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "# Few Shot Prompt:\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=few_shot_template,\n",
    "    examples=few_shot_examples,\n",
    ")\n",
    "\n",
    "# Define Final Prompt Using System prompt and Few Shot Prompt\n",
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "chain2 = prompt2 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e38e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Input Token Counts & Output Token Counts:\n",
    "\n",
    "# Combine few-shot examples into one formatted string (mimicking the actual prompt sent to the model)\n",
    "def format_few_shot_examples(examples:list):\n",
    "    formatted = \"\"\n",
    "    for ex in examples:\n",
    "        formatted += f\"Human: {ex['input']}\\nAI: {ex['output']}\\n\"\n",
    "    return formatted\n",
    "# format_few_shot_examples(examples=few_shot_examples)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate total input tokens\n",
    "def calculate_input_token_counts(system_prompt:str, user_input:str, examples:list, model:str=\"gpt-4o\") -> int:\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    # Format the full input message\n",
    "    few_shot_text = format_few_shot_examples(examples=examples)\n",
    "    full_prompt = f\"{system_prompt}\\n\\n{few_shot_text}\\nHuman: {user_input}\\n\"\n",
    "\n",
    "    return len(encoder.encode(full_prompt))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate tokens in the output (response)\n",
    "def calculate_output_token_counts(response:str, model:str=\"gpt-4o\") -> int:\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    return len(encoder.encode(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "596e1509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Indus Valley Civilization, one of the world's oldest urban cultures, is significant in Indian history for several reasons:\n",
       "\n",
       "1. **Urban Planning**: It showcased advanced urban planning with well-organized cities like Harappa and Mohenjo-Daro, featuring grid layouts, drainage systems, and brick houses.\n",
       "\n",
       "2. **Trade and Economy**: The civilization engaged in extensive trade with neighboring regions, indicating a robust economy.\n",
       "\n",
       "3. **Writing System**: It had a script that remains undeciphered, suggesting a complex communication system.\n",
       "\n",
       "4. **Architecture and Art**: The civilization is known for its impressive architecture and artifacts, including pottery, seals, and sculptures.\n",
       "\n",
       "5. **Cultural Influence**: It laid the cultural and technological foundation for subsequent Indian societies. \n",
       "\n",
       "If you'd like to know more about any of these points, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Token Counts:  510\n",
      "Output Token Counts:  172\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the Indus Valley Civilization in Indian history?\"\n",
    "response = chain2.invoke({\"input\": query})\n",
    "response = response.content\n",
    "\n",
    "\n",
    "display(Markdown(response))\n",
    "print()\n",
    "\n",
    "print(\"Input Token Counts: \", calculate_input_token_counts(system_prompt=system_prompt, user_input=query, examples=few_shot_examples))\n",
    "print(\"Output Token Counts: \", calculate_output_token_counts(response=response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341acb0",
   "metadata": {},
   "source": [
    "### **Example 03:**\n",
    "\n",
    "* Here I use both `system_prompt`, `few_shot_prompt` & `memory` concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca122b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31d7da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write System Prompt:\n",
    "system_prompt = (\n",
    "    \"You are an AI Assistant named 'Lily,' specializing in answering the questions related to INDIAN History. \"\n",
    "    \"This AI Assistant is designed by Dibyendu Biswas, a Generative AI Engineer. \"\n",
    "    \"You provide clear, step-by-step explanations and encourage students to learn. \"\n",
    "    \"If a question is unclear, ask for clarification. \"\n",
    "    \"If you don't know the answer, say 'I don't know. \"\n",
    "    \"Use 5 to 10 sentences maximum and keep the answer concise. \"\n",
    ")\n",
    "\n",
    "\n",
    "# Define Few-Shot Prompt Template using Few Examples:\n",
    "few_shot_examples = [\n",
    "    {'input': 'Hello', 'output': 'Hi there! How can I help you today?'},\n",
    "    {'input': 'What is your name?', 'output': 'I‚Äôm Lily, your assistant, specializing in answering the questions related to INDIAN History'},\n",
    "    {'input': 'How are you?', 'output': 'I‚Äôm doing great, thanks for asking! How about you?'},\n",
    "    {'input': 'Tell me a joke', 'output': 'Why don‚Äôt skeletons fight each other? They don‚Äôt have the guts!'},\n",
    "    {'input': 'What time is it?', 'output': 'I‚Äôm not able to tell the time, but you can check your device!'},\n",
    "    {'input': 'Goodbye', 'output': 'Goodbye! Have a great day!'},\n",
    "    {'input': 'Can you help me?', 'output': 'Of course! What do you need help with?'},\n",
    "    {'input': 'What is the weather like?', 'output': 'I‚Äôm unable to check real-time weather, but you can look it up online!'},\n",
    "    {'input': 'Set a reminder', 'output': 'I can‚Äôt set reminders, but I can help you with other things!'},\n",
    "    {'input': 'Where are you from?', 'output': 'I don‚Äôt have a specific place, but I‚Äôm here to assist you wherever you are!'},\n",
    "    {'input': 'What can you do?', 'output': 'I can answer questions, tell jokes, help with tasks, and more! What do you need today?'},\n",
    "    {'input': 'Help me with math', 'output': 'Sure! What math problem would you like help with?'},\n",
    "    {'input': 'I am bored', 'output': 'Let‚Äôs do something fun! Want to hear a joke or maybe try a quiz?'},\n",
    "    {'input': 'What is 5 + 7?', 'output': '5 + 7 equals 12!'},\n",
    "    {'input': 'How do I cook pasta?', 'output': 'Boil water, add pasta, cook for 8-12 minutes, drain, and enjoy!'},\n",
    "    {'input': 'Tell me a fun fact', 'output': 'Did you know? A day on Venus is longer than a year on Venus!'},\n",
    "    {'input': 'What is your favorite color?', 'output': 'I don‚Äôt have a favorite color, but I think blue is nice!'}\n",
    "]\n",
    "\n",
    "# Few Shot Template:\n",
    "few_shot_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "# Few Shot Prompt:\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=few_shot_template,\n",
    "    examples=few_shot_examples,\n",
    ")\n",
    "\n",
    "# Define Final Prompt Using System prompt and Few Shot Prompt\n",
    "prompt3 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    few_shot_prompt,\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "chain3 = prompt3 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa9055fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the chat history in a dictionary:\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5bf66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversational_rag_chain:\n",
    "\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    chain3,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33101fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Dunction to Calculate the Input Token Counts & Output Token Counts:\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def get_token_usage_from_store(session_id:str, system_prompt:str=system_prompt, \n",
    "                               few_shot_examples:list=few_shot_examples, history:dict=store, model=\"gpt-4o\"):\n",
    "    \n",
    "    history = history[session_id].messages\n",
    "    if not history:\n",
    "        return 0, 0\n",
    "    \n",
    "    system_text = system_prompt\n",
    "    few_shot_text = \"\\n\".join(f\"Human: {ex['input']}\\nAI: {ex['output']}\" for ex in few_shot_examples)\n",
    "    chat_history_text = \"\"\n",
    "\n",
    "    for msg in history[:-1]:  # exclude last if AI response\n",
    "        role = \"Human\" if msg.type == \"human\" else \"AI\"\n",
    "        chat_history_text += f\"{role}: {msg.content}\\n\"\n",
    "\n",
    "    last_user = [m for m in history if m.type == \"human\"][-1].content\n",
    "    last_ai = [m for m in history if m.type == \"ai\"][-1].content # Last Resoinse that is AI's response\n",
    "\n",
    "\n",
    "    full_prompt_text = f\"System: {system_text}\\n{few_shot_text}\\n{chat_history_text}Human: {last_user}\"\n",
    "\n",
    "\n",
    "    input_tokens = count_tokens(full_prompt_text, model=model)\n",
    "    output_tokens = count_tokens(last_ai, model=model)\n",
    "\n",
    "    print(\"Input Token Counts: \", input_tokens)\n",
    "    print(\"Output Token Counts: \", output_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb066a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = conversational_chain.invoke(\n",
    "    {\"input\": \"What is INDIA?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "851b8dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "India is a country located in South Asia. It is the seventh-largest country by land area and the second-most populous country in the world. India has a rich and diverse history, with ancient civilizations like the Indus Valley Civilization and historic empires such as the Maurya and Gupta Empires. It gained independence from British rule in 1947 and is known for its cultural diversity, languages, traditions, and significant contributions to art, science, and philosophy. The capital city is New Delhi, and the country is known for landmarks such as the Taj Mahal and its vibrant festivals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Token Counts:  508\n",
      "Output Token Counts:  116\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(ans.content))\n",
    "print()\n",
    "\n",
    "get_token_usage_from_store(session_id=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d36a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Shyam! It's great to meet you. Working at TCS as a Software Engineer sounds exciting. Kolkata is a city rich in culture and history. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Token Counts:  684\n",
      "Output Token Counts:  38\n"
     ]
    }
   ],
   "source": [
    "ans = conversational_chain.invoke(\n",
    "    {\"input\": \"Hey, My Name is Shyam, I am working in TCS, as a Software Engineer. I am from Kolkata, West Bengal, India.\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")\n",
    "\n",
    "display(Markdown(ans.content))\n",
    "print()\n",
    "\n",
    "get_token_usage_from_store(session_id=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15eef813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You mentioned that your name is Shyam, you work as a Software Engineer at TCS, and you're from Kolkata, West Bengal, India. Is there anything else you'd like to add or discuss?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Token Counts:  716\n",
      "Output Token Counts:  40\n"
     ]
    }
   ],
   "source": [
    "ans = conversational_chain.invoke(\n",
    "    {\"input\": \"Tell me about Shyam in your recent conversation.\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")\n",
    "\n",
    "display(Markdown(ans.content))\n",
    "print()\n",
    "\n",
    "get_token_usage_from_store(session_id=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75874b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is INDIA?', additional_kwargs={}, response_metadata={}), AIMessage(content='India is a country located in South Asia. It is the seventh-largest country by land area and the second-most populous country in the world. India has a rich and diverse history, with ancient civilizations like the Indus Valley Civilization and historic empires such as the Maurya and Gupta Empires. It gained independence from British rule in 1947 and is known for its cultural diversity, languages, traditions, and significant contributions to art, science, and philosophy. The capital city is New Delhi, and the country is known for landmarks such as the Taj Mahal and its vibrant festivals.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 570, 'total_tokens': 687, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BMvBq5INRpu9t868Zd83Bn58ZrCzi', 'finish_reason': 'stop', 'logprobs': None}, id='run-00b62632-08ea-40e6-b290-1112c0cb8b23-0', usage_metadata={'input_tokens': 570, 'output_tokens': 117, 'total_tokens': 687, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='Hey, My Name is Shyam, I am working in TCS, as a Software Engineer. I am from Kolkata, West Bengal, India.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Shyam! It's great to meet you. Working at TCS as a Software Engineer sounds exciting. Kolkata is a city rich in culture and history. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 724, 'total_tokens': 763, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BMvBtRSd9I6mVeW2IeP7lxBHZu6rk', 'finish_reason': 'stop', 'logprobs': None}, id='run-14dc92d6-679a-41da-81ce-e9dc83800642-0', usage_metadata={'input_tokens': 724, 'output_tokens': 39, 'total_tokens': 763, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='Tell me about Shyam in your recent conversation.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"You mentioned that your name is Shyam, you work as a Software Engineer at TCS, and you're from Kolkata, West Bengal, India. Is there anything else you'd like to add or discuss?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 780, 'total_tokens': 821, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_92f14e8683', 'id': 'chatcmpl-BMvCOJt9Ihzab3PSPLWaytNhrPXk8', 'finish_reason': 'stop', 'logprobs': None}, id='run-a9a12ef0-b4b8-4de8-a3a9-5c2867463bf9-0', usage_metadata={'input_tokens': 780, 'output_tokens': 41, 'total_tokens': 821, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411fbc50",
   "metadata": {},
   "source": [
    "#### **Extract the Tokens count from ChatHistory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00769c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction 1:\n",
      "  User Query: What is INDIA?\n",
      "  AI Response: India is a country located in South Asia. It is the seventh-largest country by land area and the second-most populous country in the world. India has a rich and diverse history, with ancient civilizations like the Indus Valley Civilization and historic empires such as the Maurya and Gupta Empires. It gained independence from British rule in 1947 and is known for its cultural diversity, languages, traditions, and significant contributions to art, science, and philosophy. The capital city is New Delhi, and the country is known for landmarks such as the Taj Mahal and its vibrant festivals.\n",
      "  Token Count: Input Tokens: 570, Output Tokens: 117, Total Tokens: 687\n",
      "----------------------------------------\n",
      "Interaction 2:\n",
      "  User Query: Hey, My Name is Shyam, I am working in TCS, as a Software Engineer. I am from Kolkata, West Bengal, India.\n",
      "  AI Response: Hi Shyam! It's great to meet you. Working at TCS as a Software Engineer sounds exciting. Kolkata is a city rich in culture and history. How can I assist you today?\n",
      "  Token Count: Input Tokens: 724, Output Tokens: 39, Total Tokens: 763\n",
      "----------------------------------------\n",
      "Interaction 3:\n",
      "  User Query: Tell me about Shyam in your recent conversation.\n",
      "  AI Response: You mentioned that your name is Shyam, you work as a Software Engineer at TCS, and you're from Kolkata, West Bengal, India. Is there anything else you'd like to add or discuss?\n",
      "  Token Count: Input Tokens: 780, Output Tokens: 41, Total Tokens: 821\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to process the chat history\n",
    "def extract_chat_details(chat_history):\n",
    "    details = []\n",
    "\n",
    "    # Loop through the dictionary's values (which are InMemoryChatMessageHistory instances)\n",
    "    for key, chat_data in chat_history.items():\n",
    "        # Accessing the 'messages' attribute from the InMemoryChatMessageHistory instance\n",
    "        if hasattr(chat_data, 'messages'):\n",
    "            messages = chat_data.messages  # Access the messages list\n",
    "\n",
    "            # Process pairs of (Human -> AI)\n",
    "            for i in range(0, len(messages), 2):  # Assuming pairs (Human -> AI)\n",
    "                user_message = messages[i]\n",
    "                ai_message = messages[i+1]  # The next message should be AI's response\n",
    "\n",
    "                # Extracting relevant data\n",
    "                user_query = user_message.content\n",
    "                ai_response = ai_message.content\n",
    "                token_usage = ai_message.response_metadata.get('token_usage', {})\n",
    "                input_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                output_tokens = token_usage.get('completion_tokens', 0)\n",
    "                total_tokens = token_usage.get('total_tokens', 0)\n",
    "\n",
    "                details.append({\n",
    "                    'user_query': user_query,\n",
    "                    'ai_response': ai_response,\n",
    "                    'input_tokens': input_tokens,\n",
    "                    'output_tokens': output_tokens,\n",
    "                    'total_tokens': total_tokens\n",
    "                })\n",
    "\n",
    "    return details\n",
    "\n",
    "# Function to print chat details\n",
    "def print_chat_details(details):\n",
    "    for idx, chat in enumerate(details):\n",
    "        print(f\"Interaction {idx + 1}:\")\n",
    "        print(f\"  User Query: {chat['user_query']}\")\n",
    "        print(f\"  AI Response: {chat['ai_response']}\")\n",
    "        print(f\"  Token Count: Input Tokens: {chat['input_tokens']}, Output Tokens: {chat['output_tokens']}, Total Tokens: {chat['total_tokens']}\")\n",
    "        print('-' * 40)\n",
    "\n",
    "# Assuming 'store' is a dictionary containing InMemoryChatMessageHistory instances\n",
    "chat_details = extract_chat_details(chat_history=store)\n",
    "\n",
    "# Print extracted details\n",
    "print_chat_details(chat_details)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429044e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3984c7a",
   "metadata": {},
   "source": [
    "## **References:**\n",
    "\n",
    "* https://www.ibm.com/think/topics/context-window\n",
    "* https://github.com/dibyendubiswas1998/Generative-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012dd0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitutor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
