{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867fd6a4",
   "metadata": {},
   "source": [
    "# **Explore Different Prompting Techniques:**\n",
    "\n",
    "* Without Prompt,\n",
    "* Zero-Shot Prompt,\n",
    "* One-Shot Prompt,\n",
    "* Few-Shot Prompt,\n",
    "* Chain-of-Thought Prompt,\n",
    "* Tree-of-Thought Prompt,\n",
    "* Role-Based Prompting,\n",
    "* N-Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c95ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa4b194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c74c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm(model_name:str=\"gpt-4o\", temperature: float=0.2, max_tokens:int=2000) -> OpenAI:\n",
    "    llm = ChatOpenAI(model_name=model_name, temperature=temperature, max_tokens=max_tokens)\n",
    "    return llm\n",
    "\n",
    "llm = load_llm(model_name=\"gpt-4o\", temperature=0.8, max_tokens=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a5d0a",
   "metadata": {},
   "source": [
    "## **1. Without Prompt:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7eda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "India is a diverse and culturally rich country located in South Asia. It is the seventh-largest country in the world by land area and the second-most populous, with over 1.4 billion people. India is known for its vast array of languages, religions, and traditions, making it one of the most culturally diverse countries globally.\n",
       "\n",
       "**Geography and Climate**: India has a varied landscape that includes the Himalayan mountain range in the north, fertile plains, deserts in the west, and coastal regions in the south. The climate also varies widely, from the tropical south to the temperate north.\n",
       "\n",
       "**History**: India has a long and complex history that dates back to prehistoric times. It is the birthplace of major religions such as Hinduism, Buddhism, Jainism, and Sikhism. India was a major center for trade and culture throughout ancient and medieval times. It was colonized by the British Empire in the 19th century and gained independence in 1947.\n",
       "\n",
       "**Culture**: Indian culture is renowned for its diversity and richness. It has a thriving arts scene, including music, dance, and cinema, with Bollywood being one of the largest film industries in the world. Indian cuisine is famous globally, known for its use of spices and flavors.\n",
       "\n",
       "**Politics and Economy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 01:\n",
    "\n",
    "res = llm.invoke(\"Tell me something about India.\")\n",
    "display(Markdown(res.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b96ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are responsible for creating a new software product. \\nNow, whatever question is asked by the user to build the product, \\nplease answer in a way that the user can easily understand. \\nDo not answer questions that are not related to building a software product.\\n\\nNow, here is the user's question:\\nTell me something about India\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 02:\n",
    "\n",
    "prompt = HumanMessage(content=\"\"\"\n",
    "You are responsible for creating a new software product. \n",
    "Now, whatever question is asked by the user to build the product, \n",
    "please answer in a way that the user can easily understand. \n",
    "Do not answer questions that are not related to building a software product.\n",
    "\n",
    "Now, here is the user's question:\n",
    "\"\"\")\n",
    "\n",
    "query = \"Tell me something about India\"\n",
    "\n",
    "# Merge the prompt and query\n",
    "final_input = prompt.content + query\n",
    "final_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df1f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm here to help with questions related to building a software product. If you have any questions about software development, design, or implementation, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = llm.invoke(final_input)\n",
    "display(Markdown(res.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f75038",
   "metadata": {},
   "source": [
    "## **2. Zero-Shot Prompt:**\n",
    "\n",
    "**This involves giving the AI a task without any prior examples. You describe what you want in detail, assuming the AI has no prior knowledge of the task**. <br>\n",
    "\n",
    "Zero-shot prompting is a method in natural language processing (NLP) where a language model is given a task without any prior training or fine-tuning on task-specific examples. The model is expected to perform the task based solely on its pre-trained knowledge and the information provided in the prompt. <br>\n",
    "\n",
    "Zero-shot prompting relies on the model's ability to generalize from its training data to handle new, unseen tasks or questions. **The prompt must be designed carefully to provide sufficient context and clarity so that the model understands the task**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce7630cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Zero-shot prompting in natural language processing involves assigning a task to an AI model without prior examples or specific training on that task. The model is expected to complete the task using its pre-existing knowledge and the details provided in the prompt. This method relies on the model's ability to generalize from its prior training to address new and unfamiliar tasks, requiring well-crafted prompts for clarity and context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You are a highly intelligent assistant that can summarize text effectively.\n",
    "Please summarize the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "query = \"\"\"\n",
    "This involves giving the AI a task without any prior examples. You describe what you want in detail,\n",
    "assuming the AI has no prior knowledge of the task.\n",
    "\n",
    "Zero-shot prompting is a method in natural language processing (NLP) where a language model is given a\n",
    "task without any prior training or fine-tuning on task-specific examples. The model is expected to\n",
    "perform the task based solely on its pre-trained knowledge and the information provided in the prompt.\n",
    "\n",
    "Zero-shot prompting relies on the model's ability to generalize from its training data to handle new,\n",
    "unseen tasks or questions. The prompt must be designed carefully to provide sufficient context and\n",
    "clarity so that the model understands the task.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = chain.invoke(query)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc8cdd",
   "metadata": {},
   "source": [
    "## **3. One-Shot Prompt:**\n",
    "\n",
    "<u>**You provide one example along with your prompt**. This helps the AI understand the context or format you’re expecting.</u> <br>\n",
    "\n",
    "One-shot prompting involves providing the model with a single example of the task before asking it to perform a similar task. This technique gives the model a concrete example to follow, improving the quality of its output compared to zero-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9a218fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['english'], input_types={}, partial_variables={}, template='You are a helpful AI assistant, your name is Lili, designed by Dibyendu Biswas, an AI/ML Engineer.\\nYour tasks is to translate the sentence from English to Bengali only.\\n\\n\\n\\nExample:\\nEnglish: How are you?\\nBengali: কেমন আছো\\n\\nEnglish: {english}\\nBengali:\\n')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"You are a helpful AI assistant, your name is Lili, designed by Dibyendu Biswas, an AI/ML Engineer.\n",
    "Your tasks is to translate the sentence from English to Bengali only.\\n\\n\n",
    "\n",
    "Example:\n",
    "English: How are you?\n",
    "Bengali: কেমন আছো\n",
    "\n",
    "English: {english}\n",
    "Bengali:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['english']\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525b0efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আমার সম্পর্কে কিছু বলো।'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke(\"Tell me something about yourself.\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c753cd",
   "metadata": {},
   "source": [
    "## **4. Few-Shot Prompt:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6f7027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are an AI Tutor, named 'Lily' specializing in Generative AI for K-12 students.This AI Tutor Designed by Dibyendu Biswas, an AI/ML EngineerYou provide clear, step-by-step explanations and encourage students to learn. If a question is unclear, ask for clarification.Use four sentences maximum and keep the answer concise.\"), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'What is an autonomous agent in LLMs?', 'output': 'Autonomous agents are systems that independently perform tasks using an LLM as their reasoning core, often involving planning, action execution, and reflection.'}, {'input': 'What is the role of a planner in an agent?', 'output': 'The planner generates a sequence of actions to achieve a specific goal.'}, {'input': 'How does the ReAct framework work in LLM-based agents?', 'output': 'ReAct combines reasoning and action to allow agents to solve problems and retrieve necessary information iteratively.'}, {'input': 'What is the benefit of reflection in agents?', 'output': 'Reflection improves an agent’s future decisions by analyzing past actions and outcomes.'}, {'input': 'Define a task decomposition approach in LLM agents.', 'output': 'Task decomposition breaks complex tasks into smaller subtasks that agents can execute sequentially or concurrently.'}, {'input': 'What is the significance of tools in agent-based systems?', 'output': 'Tools provide external capabilities like APIs, calculators, or databases for agents to interact with the real world.'}, {'input': 'What are multi-agent systems?', 'output': 'Multi-agent systems involve several agents collaborating to solve a task, often simulating teamwork.'}, {'input': 'How do self-improvement mechanisms help LLM agents?', 'output': 'Agents refine their strategies by learning from successes and failures over multiple iterations.'}, {'input': 'Explain the PEA architecture for agents.', 'output': 'PEA stands for Plan, Execute, and Assess, which outlines a structured agent workflow.'}, {'input': 'How do LLM agents handle ambiguous tasks?', 'output': 'They use iterative clarification, asking follow-up questions or retrieving additional context to resolve ambiguity.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_examples = [\n",
    "    {\"input\": \"What is an autonomous agent in LLMs?\", \"output\": \"Autonomous agents are systems that independently perform tasks using an LLM as their reasoning core, often involving planning, action execution, and reflection.\"},\n",
    "    {\"input\": \"What is the role of a planner in an agent?\", \"output\": \"The planner generates a sequence of actions to achieve a specific goal.\"},\n",
    "    {\"input\": \"How does the ReAct framework work in LLM-based agents?\", \"output\": \"ReAct combines reasoning and action to allow agents to solve problems and retrieve necessary information iteratively.\"},\n",
    "    {\"input\": \"What is the benefit of reflection in agents?\", \"output\": \"Reflection improves an agent’s future decisions by analyzing past actions and outcomes.\"},\n",
    "    {\"input\": \"Define a task decomposition approach in LLM agents.\", \"output\": \"Task decomposition breaks complex tasks into smaller subtasks that agents can execute sequentially or concurrently.\"},\n",
    "    {\"input\": \"What is the significance of tools in agent-based systems?\", \"output\": \"Tools provide external capabilities like APIs, calculators, or databases for agents to interact with the real world.\"},\n",
    "    {\"input\": \"What are multi-agent systems?\", \"output\": \"Multi-agent systems involve several agents collaborating to solve a task, often simulating teamwork.\"},\n",
    "    {\"input\": \"How do self-improvement mechanisms help LLM agents?\", \"output\": \"Agents refine their strategies by learning from successes and failures over multiple iterations.\"},\n",
    "    {\"input\": \"Explain the PEA architecture for agents.\", \"output\": \"PEA stands for Plan, Execute, and Assess, which outlines a structured agent workflow.\"},\n",
    "    {\"input\": \"How do LLM agents handle ambiguous tasks?\", \"output\": \"They use iterative clarification, asking follow-up questions or retrieving additional context to resolve ambiguity.\"},\n",
    "]\n",
    "\n",
    "# Few Shot Template:\n",
    "few_shot_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Few Shot Prompt:\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=few_shot_template,\n",
    "    examples=few_shot_examples,\n",
    ")\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an AI Tutor, named 'Lily' specializing in Generative AI for K-12 students.\"\n",
    "    \"This AI Tutor Designed by Dibyendu Biswas, an AI/ML Engineer\"\n",
    "    \"You provide clear, step-by-step explanations and encourage students to learn. \"\n",
    "    \"If a question is unclear, ask for clarification.\"\n",
    "    \"Use four sentences maximum and keep the answer concise.\"\n",
    ")\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c251b43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Few-shot prompting involves providing an LLM with a few examples within the prompt to guide its response or task performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "display(Markdown(chain.invoke(\"What is Few-Shot Prompting?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b6b36",
   "metadata": {},
   "source": [
    "## **5. Chain-of-Thought Prompt:**\n",
    "\n",
    "**Here, you ask the AI to detail its thought process step-by-step. This is particularly useful for complex reasoning tasks.**\n",
    "\n",
    "\n",
    "Chain-of-Thought (CoT) prompting involves guiding the model **to generate intermediate reasoning steps before arriving at a final answer**. This approach helps in complex tasks where a direct answer might not capture the entire reasoning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90cb2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template=\"You are a helpful AI assistant, your name is Lili, designed by Dibyendu Biswas, an AI/ML Engineer.\\nYour tasks is to answers the user's query in below following format or helps users solve problems step by step:\\n\\nQuery: Your warehouse has 5 pallets of widgets. You purchase 2 more shipments of widgets. Each shipment contains 3 pallets. How many pallets of widgets do you have now?\\nAnswer: The warehouse started with 5 pallets of widgets. 2 shipments of 3 pallets each is 6 pallets. 5 pallets + 6 pallets = 11 pallets. The answer is 11 pallets.\\n\\nQuery: {question}\\n\\n\\nLet's think step by step.\\n\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"You are a helpful AI assistant, your name is Lili, designed by Dibyendu Biswas, an AI/ML Engineer.\n",
    "Your tasks is to answers the user's query in below following format or helps users solve problems step by step:\n",
    "\n",
    "Query: Your warehouse has 5 pallets of widgets. You purchase 2 more shipments of widgets. \\\n",
    "Each shipment contains 3 pallets. How many pallets of widgets do you have now?\n",
    "Answer: The warehouse started with 5 pallets of widgets. 2 shipments of 3 pallets each is 6 pallets. \\\n",
    "5 pallets + 6 pallets = 11 pallets. The answer is 11 pallets.\n",
    "\n",
    "Query: {question}\n",
    "\n",
    "\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7dd6ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine how much is left in the budget, let's analyze the given information step by step:\n",
       "\n",
       "1. The initial budget for the marketing campaign is $20,000.\n",
       "2. An additional $20,000 is allocated for the marketing campaign, increasing the total budget. \n",
       "3. Another $6,000 is added from other savings.\n",
       "\n",
       "Now, let's calculate the total budget:\n",
       "\n",
       "- Start with the initial $20,000.\n",
       "- Add the additional $20,000 allocated: \\( 20,000 + 20,000 = 40,000 \\).\n",
       "- Add the $6,000 from other savings: \\( 40,000 + 6,000 = 46,000 \\).\n",
       "\n",
       "Therefore, the total amount in the budget for the marketing campaign is $46,000.\n",
       "\n",
       "The answer is $46,000 in the budget."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke(\"Your finance department has $20,000 in the budget for a marketing campaign. I further allocate $20,000 for a marketing campaign and add $6,000 from other savings. How much is left in the budget?\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea2ccd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To find the average speed of the train, we can use the formula for average speed, which is:\n",
       "\n",
       "\\[\n",
       "\\text{Average speed} = \\frac{\\text{Total distance}}{\\text{Total time}}\n",
       "\\]\n",
       "\n",
       "Let's break down the problem step by step:\n",
       "\n",
       "1. **Determine the Total Distance:**\n",
       "   - The train travels a total distance of 60 kilometers.\n",
       "\n",
       "2. **Determine the Total Time:**\n",
       "   - The total time taken by the train is 1.5 hours.\n",
       "\n",
       "3. **Apply the Formula:**\n",
       "   - Substitute the total distance and total time into the formula to find the average speed:\n",
       "   \\[\n",
       "   \\text{Average speed} = \\frac{60 \\text{ km}}{1.5 \\text{ hours}}\n",
       "   \\]\n",
       "\n",
       "4. **Calculate the Average Speed:**\n",
       "   - Perform the division:\n",
       "   \\[\n",
       "   \\text{Average speed} = 40 \\text{ km/h}\n",
       "   \\]\n",
       "\n",
       "Thus, the average speed of the train is 40 kilometers per hour."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful AI Assistant named Lily, who helps users solve problems step by step.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Let's think step by step.\n",
    "\"\"\")\n",
    "\n",
    "# Step 2: Add the LLM and Output Parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Step 3: Chain everything\n",
    "chain = cot_prompt | llm | parser\n",
    "\n",
    "# Step 4: Invoke with a reasoning-based question\n",
    "response = chain.invoke(\"If a train travels 60 km in 1.5 hours, what is its average speed in km/h?\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6036b1e",
   "metadata": {},
   "source": [
    "## **6. Tree-of-Thought Prompt:**\n",
    "\n",
    "**Tree-of-Thought (ToT) prompting expands on CoT by exploring multiple reasoning paths in parallel**, akin to a decision tree. This technique is useful for tasks that can have multiple **plausible approaches** or solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d8ace0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\nYou are Lily, a thoughtful assistant. Consider multiple possible approaches before solving.\\n\\nQuestion: {question}\\n\\nThink of at least two different ways to solve this. Then, choose the best solution.\\n\\nOption 1:\\n...\\n\\nOption 2:\\n...\\n\\nBest Answer:\\n')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are Lily, a thoughtful assistant. Consider multiple possible approaches before solving.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Think of at least two different ways to solve this. Then, choose the best solution.\n",
    "\n",
    "Option 1:\n",
    "...\n",
    "\n",
    "Option 2:\n",
    "...\n",
    "\n",
    "Best Answer:\n",
    "\"\"\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "161c47de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To address the issue of traffic congestion in large Indian cities, we need to consider various approaches that can be tailored to the unique challenges of urban environments in India. Here are two potential solutions:\n",
       "\n",
       "Option 1: Enhance Public Transportation Systems\n",
       "- **Develop Integrated Transport Networks**: Improve and expand the existing public transportation infrastructure, including buses, metro, and commuter trains, to provide more reliable and frequent services. Integrating these systems can create a seamless travel experience.\n",
       "- **Upgrade Technology**: Implement smart technologies like real-time tracking apps, digital payment systems, and efficient scheduling to make public transportation more user-friendly and efficient.\n",
       "- **Encourage Use through Incentives**: Offer incentives for using public transport, such as discounted fare passes or tax benefits, to make it a more attractive option compared to driving personal vehicles.\n",
       "\n",
       "Option 2: Implement Traffic Management and Control Measures\n",
       "- **Smart Traffic Signals**: Use AI-driven traffic signals that adapt to real-time traffic conditions, improving flow and reducing congestion at peak times.\n",
       "- **Carpool and Ride-Sharing Promotions**: Promote carpooling and ride-sharing services through dedicated lanes or reduced toll charges, thereby reducing the number of vehicles on the road.\n",
       "- **Congestion Pricing**: Introduce congestion pricing in highly congested zones"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "display(Markdown(chain.invoke(\"How can we reduce traffic in large Indian cities?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810c6ab",
   "metadata": {},
   "source": [
    "## **7. Role Based Prompting:**\n",
    "\n",
    "Use persona-based **instructions for behavior control**. **Great for tone, context, or expert emulation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a316f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a professional Indian History professor at a university.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional Indian History professor at a university.\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44ffd295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! The Battle of Plassey, fought on June 23, 1757, was a pivotal confrontation between the British East India Company led by Robert Clive and the Nawab of Bengal, Siraj-ud-Daulah. This battle marked a significant turning point in Indian history due to several key reasons:\n",
       "\n",
       "1. **Establishment of British Power**: The victory at Plassey laid the foundation for British colonial rule in India. It marked the beginning of British political dominance in India, eventually leading to the establishment of British rule over the entire subcontinent.\n",
       "\n",
       "2. **Control over Bengal**: Bengal was one of the most prosperous and resource-rich regions in India at the time. The British gained control over Bengal's revenues, enabling the East India Company to finance its expansion and solidify its presence in India.\n",
       "\n",
       "3. **Economic Exploitation**: The control over Bengal's resources facilitated the economic exploitation of the region. The wealth extracted from Bengal contributed significantly to Britain's economic growth and its ability to finance further colonial ventures.\n",
       "\n",
       "4. **Political Strategy and Alliances**: The battle highlighted the use of political strategies and alliances in military conflicts. The British were able to win the battle, in part, due to their alliance with key Indian figures such as"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "display(Markdown(chain.invoke(\"Can you explain the importance of the Battle of Plassey?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3acc1341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Chain of Thought (CoT) prompting is a technique used in natural language processing and artificial intelligence to improve the reasoning and decision-making capabilities of AI models. It involves guiding the AI through a series of intermediate steps or reasoning processes to arrive at a solution or conclusion. By breaking down a complex problem into smaller, more manageable parts, CoT prompting helps models generate more accurate and coherent responses.\n",
       "\n",
       "In practice, Chain of Thought prompting might involve explicitly instructing the model to consider various aspects of a problem sequentially, much like a human would go through a logical reasoning process. This can be particularly useful in tasks that require multi-step reasoning, such as mathematical problem-solving, complex question answering, and more nuanced decision-making scenarios. By encouraging a structured approach to problem-solving, CoT prompting aims to enhance the AI's ability to handle complex queries more effectively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(chain.invoke(\"What is Chain of Thought (CoT) prompting?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005cd12",
   "metadata": {},
   "source": [
    "## **8. N-Shot Prompting:**\n",
    "\n",
    "Similart to Few-Shot Prompt with n-examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa36e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82121ea2",
   "metadata": {},
   "source": [
    "## **Links:**\n",
    "\n",
    "https://github.com/dibyendubiswas1998/Generative-AI/tree/main/Prompt%20Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad60dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitutor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
